{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ResidualBlock(torch.nn.Module):\n",
    "    \"\"\"A Conv2D block with skip connections.\n",
    "\n",
    "    A single ResidualBlock module computes the following:\n",
    "        `y = relu(x + norm(conv(relu(norm(conv(x))))))`\n",
    "    where `x` is the input, `y` is the output, `norm` is a 2D batch norm and `conv` is\n",
    "    a 2D convolution with kernel of size 3, stride 1 and padding 1.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, in_channels: int, out_channels: int):\n",
    "        \"\"\"Init the ResidualBlock.\n",
    "\n",
    "        Args:\n",
    "            in_channels: Number of input channels.\n",
    "            out_channels: Number of output channels.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "\n",
    "        self.conv1 = torch.nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.conv2 = torch.nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1)\n",
    "        self.norm1 = torch.nn.BatchNorm2d(num_features=out_channels)\n",
    "        self.norm2 = torch.nn.BatchNorm2d(num_features=out_channels)\n",
    "        self.relu = torch.nn.ReLU()\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Compute the forward pass of the ResidualBlock.\n",
    "\n",
    "        Args:\n",
    "            x: The input.\n",
    "\n",
    "        Returns:\n",
    "            The output after applying the residual block. See the class description\n",
    "            for more details.\n",
    "        \"\"\"\n",
    "        y = self.conv1(x)\n",
    "        y = self.norm1(y)\n",
    "        y = self.relu(y)\n",
    "        y = self.conv2(y)\n",
    "        y = self.norm2(y)\n",
    "        print(y.shape, x.shape)\n",
    "        return self.relu(y + x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Conv2DEncoder(torch.nn.Module):\n",
    "    \"\"\"An image encoder based on 2D convolutions.\n",
    "\n",
    "    Based on: https://github.com/lucidrains/DALLE-pytorch/blob/main/dalle_pytorch/dalle_pytorch.py\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        *,\n",
    "        input_channels: int = 3,\n",
    "        output_channels: int = 512,\n",
    "        hidden_size: int = 64,\n",
    "        num_layers: int = 3,\n",
    "        num_resnet_blocks: int = 1,\n",
    "    ):\n",
    "        \"\"\"Init the encoder.\n",
    "\n",
    "        Args:\n",
    "            input_channels: Number of input channels.\n",
    "            output_channels: Number of the output channels.\n",
    "            hidden_size: Number of channels in the intermediate hidden layers.\n",
    "            num_layers: Number of hidden layers.\n",
    "            num_resnet_blocks: Number of resnet blocks added after each layer.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        layers_list: list[torch.nn.Module] = [\n",
    "            torch.nn.Conv2d(input_channels, hidden_size, kernel_size=1)\n",
    "        ]\n",
    "        for _ in range(num_layers):\n",
    "            layers_list.extend(\n",
    "                [ResidualBlock(hidden_size, hidden_size) for _ in range(num_resnet_blocks)]\n",
    "            )\n",
    "            layers_list.append(\n",
    "                torch.nn.Conv2d(hidden_size, hidden_size, kernel_size=4, stride=2, padding=1)\n",
    "            )\n",
    "            layers_list.append(torch.nn.ReLU())\n",
    "\n",
    "        layers_list.append(torch.nn.Conv2d(hidden_size, output_channels, kernel_size=1))\n",
    "        self.layers = torch.nn.Sequential(*layers_list)\n",
    "\n",
    "    def forward(self, x: torch.Tensor) -> torch.Tensor:\n",
    "        \"\"\"Encode an image.\n",
    "\n",
    "        Args:\n",
    "            x: The input image of shape `(batch, input_channels, in_width, in_height)`\n",
    "\n",
    "        Returns:\n",
    "            The encoder image of shape `(batch, output_channels, out_width, out_height)`\n",
    "        \"\"\"\n",
    "        return self.layers(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_model = Conv2DEncoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Conv2DEncoder(\n",
      "  (layers): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(1, 1), stride=(1, 1))\n",
      "    (1): ResidualBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (norm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (2): Conv2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (3): ReLU()\n",
      "    (4): ResidualBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (norm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (5): Conv2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (6): ReLU()\n",
      "    (7): ResidualBlock(\n",
      "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (norm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU()\n",
      "    )\n",
      "    (8): Conv2d(64, 64, kernel_size=(4, 4), stride=(2, 2), padding=(1, 1))\n",
      "    (9): ReLU()\n",
      "    (10): Conv2d(64, 512, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(enc_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 64, 256, 256]) torch.Size([1, 64, 256, 256])\n",
      "torch.Size([1, 64, 128, 128]) torch.Size([1, 64, 128, 128])\n",
      "torch.Size([1, 64, 64, 64]) torch.Size([1, 64, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1, 3, 256, 256)\n",
    "y = enc_model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512, 32, 32])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
